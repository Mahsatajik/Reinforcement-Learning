{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_2_RL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LhwuIHgBF_UU",
        "aAUMhHj7ekjb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27uYYY_1OTvF",
        "outputId": "a7c119a2-182b-4eb6-bda8-1672d0fd0c96"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zksM_eClOX6r",
        "outputId": "23dbc599-c8f6-4f6d-dbd2-17c5220fcec3"
      },
      "source": [
        "%cd '/content/drive/My Drive/RL/amalearn'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/RL/amalearn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyz53kYqOdCj",
        "outputId": "571f98a9-bdba-4d32-d3e2-6774d0fd29ae"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/RL/amalearn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM5INhtEOguA",
        "outputId": "c57c783e-d1a2-4bb4-e25e-7c0d9671a565"
      },
      "source": [
        "!pip install -e ."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/RL/amalearn\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from amalearn==0.1) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from amalearn==0.1) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->amalearn==0.1) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->amalearn==0.1) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->amalearn==0.1) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->amalearn==0.1) (0.16.0)\n",
            "Installing collected packages: amalearn\n",
            "  Attempting uninstall: amalearn\n",
            "    Found existing installation: amalearn 0.1\n",
            "    Can't uninstall 'amalearn'. No files were found to uninstall.\n",
            "  Running setup.py develop for amalearn\n",
            "Successfully installed amalearn-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OwEVaGLOFDd"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from amalearn.agent import AgentBase\n",
        "import csv\n",
        "import pandas as pd\n",
        "from numpy import exp"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhwuIHgBF_UU"
      },
      "source": [
        "##REWARD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H__MMOraF-9O"
      },
      "source": [
        "from amalearn.reward import RewardBase\n",
        "import numpy as np\n",
        "\n",
        "class GaussianReward(RewardBase):\n",
        "    def __init__(self, mean, std):\n",
        "        super(GaussianReward, self).__init__()\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def get_reward(self):\n",
        "        return np.random.normal(loc=self.mean, scale=self.std)\n",
        "\n",
        "\n",
        "class UniformReward(RewardBase):\n",
        "    def __init__(self, low, high):\n",
        "      super(UniformReward, self).__init__()\n",
        "      self.low = low\n",
        "      self.high = high\n",
        "\n",
        "    def get_reward(self):\n",
        "        return np.random.uniform(low=self.low, high=self.high, size=None)\n",
        "\n",
        "\n",
        "class BetaReward(RewardBase):\n",
        "    def __init__(self, a, b):\n",
        "      super(BetaReward, self).__init__()\n",
        "      self.a = a\n",
        "      self.b = b\n",
        "\n",
        "    def get_reward(self):\n",
        "        return np.random.beta(a=self.a, b=self.b, size=None)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JUotw2iFslA"
      },
      "source": [
        "def SelectPack(volumes, prices):\n",
        "  random_number = np.random.random_sample()\n",
        "  \n",
        "  \n",
        "  if random_number >= 0.33:\n",
        "    x = BetaReward(2,5).get_reward()\n",
        "    volumes_beta = []\n",
        "    for i in range(len(volumes)):\n",
        "      volumes_beta.append(volumes[i] * x)\n",
        "    selected_pack = np.argmax(volumes_beta) \n",
        "  else:\n",
        "    x = BetaReward(3,2.5).get_reward()\n",
        "    volumes_prices_beta = np.divide(volumes, prices) * x\n",
        "    selected_pack = np.argmin(volumes_prices_beta)\n",
        "  return selected_pack"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vhtb-Xi43In"
      },
      "source": [
        "class Pack:\n",
        "    def __init__(self, p, v):\n",
        "        \n",
        "        self.price = p\n",
        "        self.volume = v\n",
        "\n",
        "    def get_price(self):\n",
        "      return self.price\n",
        "    def get_volume(self):\n",
        "      return self.volume\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erb2WC2bZ0n4"
      },
      "source": [
        "##Epsilon Greedy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtiNfLmi-lJC"
      },
      "source": [
        "class EpsilonGreedyAgent(AgentBase):\n",
        "    def __init__(self, id, environment):\n",
        "        super(EpsilonGreedyAgent, self).__init__(id, environment)\n",
        "        \n",
        "        self.counts = [0 for col in range(2)]\n",
        "        self.values = [0.0 for col in range(2)]\n",
        "        self.epsilon = 0.1\n",
        "\n",
        "       \n",
        "  \n",
        "    def take_action(self) -> (object, float, bool, object , np.ndarray ):\n",
        "      available_actions = self.environment.available_actions()\n",
        "\n",
        "      random_number = np.random.random_sample()\n",
        "      if random_number >= self.epsilon:\n",
        "        action = np.argmax(self.values)\n",
        "      else:\n",
        "        action = np.random.randint(available_actions)\n",
        "\n",
        "      #plan1\n",
        "      pack1 = Pack(21, 6)\n",
        "      pack2 = Pack(35, 12)\n",
        "      #plan2\n",
        "      pack3 = Pack(12, 3)\n",
        "      pack4 = Pack(22, 8)\n",
        "\n",
        "      volumes_plan1 = np.array([pack1.get_volume(), pack2.get_volume()])\n",
        "      prices_plan1 = np.array([pack1.get_price(), pack2.get_price()])\n",
        "      volumes_plan2 = np.array([pack3.get_volume(), pack4.get_volume()])\n",
        "      prices_plan2 = np.array([pack3.get_price(), pack4.get_price()])\n",
        "\n",
        "      if action == 0:\n",
        "        selected_pack = SelectPack(volumes_plan1, prices_plan1)\n",
        "      else:\n",
        "        selected_pack = SelectPack(volumes_plan2, prices_plan2)\n",
        "      # print(selected_pack)\n",
        "      \n",
        "      obs, r, d, i = self.environment.step(selected_pack)\n",
        "\n",
        "\n",
        "      # if r > 0 :\n",
        "      #   r = math.pow(r, self.alpha)\n",
        "      # else:\n",
        "      #   r = -self.gamma*math.pow(r, self.beta)       \n",
        "      \n",
        "      # self.counts[action] = self.counts[action] + 1\n",
        "      # n = self.counts[action]\n",
        "      # value = self.values[action]\n",
        "      # new_value = ((n-1) / float(n)) * value + (1 / float(n)) * r\n",
        "      # self.values[action] = new_value\n",
        "      # print(self.values)\n",
        "      return obs, r, d, i, action, selected_pack\n",
        "    \n",
        "    def set_epsilon(self):\n",
        "      self.epsilon += 0.001\n",
        "\n",
        "  \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAUMhHj7ekjb"
      },
      "source": [
        "##Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9_wT3XIww9H"
      },
      "source": [
        "import gym\n",
        "from amalearn.environment import EnvironmentBase\n",
        "\n",
        "class MyEnvironment(EnvironmentBase):\n",
        "    def __init__(self, rewards, episode_max_length, id, container=None):\n",
        "        state_space = gym.spaces.Discrete(1)\n",
        "        action_space = gym.spaces.Discrete(len(rewards))\n",
        "\n",
        "        super(MyEnvironment, self).__init__(action_space, state_space, id, container)\n",
        "        self.arms_rewards = rewards\n",
        "        self.episode_max_length = episode_max_length\n",
        "        self.state = {\n",
        "            'length': 0,\n",
        "            'last_action': None\n",
        "        }\n",
        "\n",
        "    def calculate_reward(self, action):\n",
        "        return self.arms_rewards[action]\n",
        "\n",
        "    def terminated(self):\n",
        "        return self.state['length'] >= self.episode_max_length\n",
        "\n",
        "    def observe(self):\n",
        "        return {}\n",
        "\n",
        "    def available_actions(self):\n",
        "        return self.action_space.n\n",
        "\n",
        "    def next_state(self, action):\n",
        "        self.state['length'] += 1\n",
        "        self.state['last_action'] = action\n",
        "\n",
        "    def reset(self):\n",
        "        self.state['length'] = 0\n",
        "        self.state['last_action'] = None\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print('{}:\\taction={}'.format(self.state['length'], self.state['last_action']))\n",
        "\n",
        "    def close(self):\n",
        "        return\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSTKg9dO62Mp"
      },
      "source": [
        "##Rewards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLCVdgBvMENN",
        "outputId": "b5cde4cb-5d32-4c0c-e5a3-31cf2c328842"
      },
      "source": [
        "rewards = []\n",
        "#plan1\n",
        "pack1 = Pack(21, 6)\n",
        "pack2 = Pack(35, 12)\n",
        "#plan2\n",
        "pack3 = Pack(12, 3)\n",
        "pack4 = Pack(22, 8)\n",
        "\n",
        "prices = np.array([[pack1.get_price(), pack2.get_price()], [pack3.get_price(), pack4.get_price()]])\n",
        "volumes = np.array([[pack1.get_volume(), pack2.get_volume()], [pack3.get_volume(), pack4.get_volume()]])\n",
        "remain_volume = 1-GaussianReward(0.61,0.05).get_reward()\n",
        "rewards = prices + (prices * remain_volume)\n",
        "\n",
        "print(rewards)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30.57493604 50.95822673]\n",
            " [17.47139202 32.03088537]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPAttAr6o6k"
      },
      "source": [
        "env = MyEnvironment(rewards=rewards, episode_max_length = 1000, id = '1')\n",
        "agent1 = EpsilonGreedyAgent('1', env)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6PC-ht6hH1e"
      },
      "source": [
        "##EPSILONGREEDY_RUN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "awXWqNXmAuz0",
        "outputId": "322090f5-d9cc-4dbe-dfbf-afbe02113fec"
      },
      "source": [
        "plt.figure()\n",
        "r1 = r2 = 0\n",
        "count1 = count2 = 0\n",
        "for k in range(1,10000):\n",
        "  observation, reward, done, info, action, selected_pack = agent1.take_action()\n",
        "  if (action == 0) and (selected_pack == 0):\n",
        "    r1 += reward[0]\n",
        "    count1 +=1\n",
        "  elif (action == 0) and (selected_pack == 1):\n",
        "    r1 += reward[1]\n",
        "    count1 +=1\n",
        "  elif (action == 1) and (selected_pack == 0):\n",
        "    r2 += reward[0]\n",
        "    count2 +=1\n",
        "  else:\n",
        "    r2 += reward[1]\n",
        "    count2 +=1\n",
        "\n",
        "average_action1 = r1/count1\n",
        "if count2 == 0:\n",
        "  average_action2 = 0\n",
        "else:\n",
        "  average_action2 = r2/count2\n",
        "\n",
        "if average_action1 > average_action2:\n",
        "  optimal_action = 0\n",
        "  optimal_average = average_action1\n",
        "else:\n",
        "  optimal_action = 1\n",
        "  optimal_average = average_action2\n",
        "\n",
        "print(optimal_action)\n",
        "for i in range(10):\n",
        "  agent1.epsilon= 0.1\n",
        "  count = [0 for col in range(2)]\n",
        "  values = [0.0 for col in range(2)]\n",
        "  rewards = []\n",
        "  selected_action = []\n",
        "  REGRET = []\n",
        "  for j in range(1,1001):\n",
        "    if j % 100 == 0:\n",
        "      # print(j)\n",
        "      agent1.epsilon += 0.05\n",
        "      # print(agent1.epsilon)\n",
        "    observation, reward, done, info, action, selected_pack = agent1.take_action()\n",
        "    \n",
        "    count[action] +=1\n",
        "    if (action == 0) and (selected_pack == 0): \n",
        "      values[action] = reward[0] * (1/count[action]) + ((count[action]-1)/count[action])*values[action]\n",
        "      rewards.append(reward[0])\n",
        "    elif (action == 0) and (selected_pack == 1): \n",
        "      values[action] = reward[1] * (1/count[action]) + ((count[action]-1)/count[action])*values[action]\n",
        "      rewards.append(reward[1])\n",
        "    \n",
        "    elif (action == 1) and (selected_pack == 0): \n",
        "      values[action] = reward[0] * (1/count[action]) + ((count[action]-1)/count[action])*values[action]\n",
        "      rewards.append(reward[0])\n",
        "    else:\n",
        "      values[action] = reward[1] * (1/count[action]) + ((count[action]-1)/count[action])*values[action]\n",
        "      rewards.append(reward[1])\n",
        "    \n",
        "    selected_action.append(action)\n",
        "  \n",
        "  for k in range(len(selected_action)):\n",
        "    regret = (optimal_average - rewards[k]/k)\n",
        "    REGRET.append(regret)\n",
        "\n",
        "plt.plot(REGRET)\n",
        "plt.xlabel(\"trial\")\n",
        "plt.ylabel(\"regret\")\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}